{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 - COMP-5600\n",
    "\n",
    "## Question 1\n",
    "\n",
    "You are tasked with developing models to **predict customer churn** for a subscription-based service. Using the provided dataset, your **goal is to build two classification models: one using Logistic Regression and the other using Naive Bayes.** You will compare their performance, interpret the results, and provide insights into customer churn based on your findings. You will **use provided the Telco Customer Churn dataset**, which contains customer information such as demographic details, account features, and whether the customer has churned. Your **target variable is \"Churn,\" indicating whether a customer has left the service.**\n",
    "\n",
    "### Ensure you follow the below instructions:\n",
    "\n",
    "• Evaluate both models using the following metrics: Accuracy, Precision, Recall, F1-Score, and ROC-AUC.\n",
    "• Perform 5-fold cross-validation on both models and report the averaged results.\n",
    "• If there are any missing values (there will be!), fill them in during a pre-processing step using two of the three common strategies outlined below. Do this for the entire dataset!\n",
    "* Use the most common value in the dataset that has a value for this feature/attribute\n",
    "* Use a default value to fill in for missing values. It can be anything.\n",
    "* Drop that feature all together and use only features that have values for all data points.\n",
    "* Scale or normalize numerical features if required.\n",
    "\n",
    "\n",
    "### Ensure that your IPython notebook has text files that has the following details:\n",
    "\n",
    "* Discuss your outcomes from using your chosen preprocessing steps to handle missing data\n",
    "* Compare the performance of both models and discuss their strengths and weaknesses. Which model is more suited for this dataset and why?\n",
    "* Insights gained from your experiments.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Scores with Mode Filling: {'test_accuracy': np.float64(0.802499858861862), 'test_precision': np.float64(0.6528883458240898), 'test_recall': np.float64(0.5457513153933277), 'test_f1': np.float64(0.5944998310382755), 'test_roc_auc': np.float64(0.72049879003765)}\n",
      "Logistic Regression Scores with Median Filling: {'test_accuracy': np.float64(0.8024999596748177), 'test_precision': np.float64(0.6529012740249558), 'test_recall': np.float64(0.5457513153933277), 'test_f1': np.float64(0.5944971645329467), 'test_roc_auc': np.float64(0.7204988834790015)}\n",
      "Naive Bayes Scores with Mode Filling: {'test_accuracy': np.float64(0.7530892114007355), 'test_precision': np.float64(0.524868504886578), 'test_recall': np.float64(0.7383707760462215), 'test_f1': np.float64(0.6134822494313783), 'test_roc_auc': np.float64(0.7483899217974873)}\n",
      "Naive Bayes Scores with Median Filling: {'test_accuracy': np.float64(0.7530892114007355), 'test_precision': np.float64(0.524868504886578), 'test_recall': np.float64(0.7383707760462215), 'test_f1': np.float64(0.6134822494313783), 'test_roc_auc': np.float64(0.7483899217974873)}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "* Question 1 Code \n",
    "'''\n",
    "\n",
    "# Import necessary packages + libraries.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, train_test_split, cross_val_score, StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, make_scorer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "# Function to fill in missing values with the most frequent value.\n",
    "def fill_freq(data):\n",
    "    imp = SimpleImputer(strategy=\"most_frequent\")\n",
    "    data_in = pd.DataFrame(imp.fit_transform(data), columns=data.columns)\n",
    "    return data\n",
    "def fill_mode(data):\n",
    "    num_cols = data.select_dtypes(include=['number']).columns\n",
    "    cat_cols = data.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "    imp_med = SimpleImputer(strategy=\"most_frequent\")\n",
    "    data[num_cols] = imp_med.fit_transform(data[num_cols])\n",
    "\n",
    "    imp_const = SimpleImputer(strategy=\"most_frequent\",)\n",
    "    data[cat_cols] = imp_const.fit_transform(data[cat_cols])\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# Function to fill in missing values with the median value.\n",
    "# def fill_median(data):\n",
    "#     imp = SimpleImputer(strategy=\"constant\", fill_value=1)\n",
    "#     data[['tenure', 'MonthlyCharges']] = imp.fit_transform(data[['tenure', 'MonthlyCharges']])\n",
    "#     return data\n",
    "\n",
    "def fill_constant(data):\n",
    "    num_cols = data.select_dtypes(include=['number']).columns\n",
    "    cat_cols = data.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "    imp_med = SimpleImputer(strategy=\"median\")\n",
    "    data[num_cols] = imp_med.fit_transform(data[num_cols])\n",
    "\n",
    "    imp_const = SimpleImputer(strategy=\"constant\", fill_value=0)\n",
    "    data[cat_cols] = imp_const.fit_transform(data[cat_cols])\n",
    "\n",
    "    return data\n",
    "\n",
    "# Function to evaluate the model using 5-fold cross-validation.\n",
    "def eval_model(model, X, y):\n",
    "    \n",
    "    # Dictionary creating the different metrics to evaluate the model, using the make_scorer function.\n",
    "    metrics = {\n",
    "        'accuracy': make_scorer(accuracy_score),\n",
    "        'precision': make_scorer(precision_score),\n",
    "        'recall': make_scorer(recall_score),\n",
    "        'f1': make_scorer(f1_score),\n",
    "        'roc_auc': make_scorer(roc_auc_score)\n",
    "    }\n",
    "\n",
    "    scores = cross_validate(model, X, y, scoring=metrics, cv=5)\n",
    "    return scores\n",
    "\n",
    "\n",
    "# Load in the provided data from the Telco dataset.\n",
    "df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "\n",
    "\n",
    "# *** PREPROCESSING STEP ***\n",
    "\n",
    "# Drop the CustomerID column.\n",
    "customer_ids = df['customerID']\n",
    "df = df.drop(columns=['customerID'])\n",
    "\n",
    "# Convert the TotalCharges column to numeric, and temporarily set non-numeric values to NaN.\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "\n",
    "# Make a df copy for the median and mode fillings.\n",
    "df_mode = fill_mode(df.copy())\n",
    "\n",
    "df_median = fill_constant(df.copy())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Encoding the categorical columns for df_mode.\n",
    "\n",
    "label_encoders_mode = {}\n",
    "label_encoders_median = {}\n",
    "\n",
    "# Get the categorical columns, excluding the true output.\n",
    "mode_categorical_features = df_mode.select_dtypes(include=['object']).columns.drop('Churn')  \n",
    "median_categorical_features = df_median.select_dtypes(include=['object']).columns.drop('Churn')  \n",
    "\n",
    "\n",
    "# Iterate though each column and encode the values.\n",
    "# Store the encoders in a dictionary for later use on other data, \n",
    "# for both mode and median dataframes.\n",
    "for mode_col, med_col in zip(mode_categorical_features, median_categorical_features):\n",
    "    le_mod = LabelEncoder()\n",
    "    le_med = LabelEncoder()\n",
    "    df_mode[mode_col] = le_mod.fit_transform(df_mode[mode_col])\n",
    "    df_median[med_col] = le_med.fit_transform(df_median[med_col])\n",
    "    \n",
    "    label_encoders_mode[mode_col] = le_mod\n",
    "    label_encoders_median[med_col] = le_med\n",
    "\n",
    "## Encode the target variables for both mode and median dataframes.\n",
    "\n",
    "mode_target_encoder = LabelEncoder()\n",
    "median_target_encoder = LabelEncoder()\n",
    "\n",
    "df_mode['Churn'] = mode_target_encoder.fit_transform(df_mode['Churn'])\n",
    "df_median['Churn'] = median_target_encoder.fit_transform(df_median['Churn'])\n",
    "\n",
    "\n",
    "\n",
    "# *** MODELING STEP ***\n",
    "df_nb_mode = df_mode.copy()\n",
    "df_nb_median = df_median.copy()\n",
    "\n",
    "# Scale the data for both mode and median dataframes.\n",
    "scaler_mode = StandardScaler()\n",
    "scaler_median = StandardScaler()\n",
    "\n",
    "# Get the numerical columns, to ensure others aren't scaled.\n",
    "numerical_features = ['tenure', 'MonthlyCharges']\n",
    "\n",
    "# Scale the numerical columns.\n",
    "df_mode[numerical_features] = scaler_mode.fit_transform(df_mode[numerical_features])\n",
    "df_median[numerical_features] = scaler_median.fit_transform(df_median[numerical_features])\n",
    "\n",
    "# Split the data into training and testing sets for both mode and median dataframes.\n",
    "X_mode = df_mode.drop(columns=['Churn'])\n",
    "X_nb_mode = df_nb_mode.drop(columns=['Churn'])\n",
    "y_mode = df_mode['Churn']\n",
    "y_nb_mode = df_nb_mode['Churn']\n",
    "\n",
    "X_median = df_median.drop(columns=['Churn'])\n",
    "X_nb_median = df_nb_median.drop(columns=['Churn'])\n",
    "y_median = df_median['Churn']\n",
    "y_nb_median = df_nb_median['Churn']\n",
    "\n",
    "\n",
    "lr_mode = LogisticRegression(max_iter=7000)\n",
    "lr_median = LogisticRegression( max_iter=7000)\n",
    "\n",
    "# Create a naive bayes model for each df.\n",
    "nb_mode = GaussianNB()\n",
    "nb_median = GaussianNB()\n",
    "\n",
    "lr_mode_scores = eval_model(lr_mode, X_mode, y_mode)\n",
    "lr_median_scores = eval_model(lr_median, X_median, y_median)\n",
    "\n",
    "nb_mode_scores = eval_model(nb_mode, X_nb_mode, y_nb_mode)\n",
    "nb_median_scores = eval_model(nb_median, X_nb_median, y_nb_median)\n",
    "\n",
    "# Calculate the average scores for each metric, for both mode and median dataframes.\n",
    "lr_mode_scores_avg = {metric: scores.mean() for metric, scores in lr_mode_scores.items() if 'test_' in metric}\n",
    "lr_median_scores_avg = {metric: scores.mean() for metric, scores in lr_median_scores.items() if 'test_' in metric}\n",
    "\n",
    "nb_mode_scores_avg = {metric: scores.mean() for metric, scores in nb_mode_scores.items() if 'test_' in metric}\n",
    "nb_median_scores_avg = {metric: scores.mean() for metric, scores in nb_median_scores.items() if 'test_' in metric}\n",
    "\n",
    "# Output the results\n",
    "print(\"Logistic Regression Scores with Mode Filling:\", lr_mode_scores_avg)\n",
    "print(\"Logistic Regression Scores with Median Filling:\", lr_median_scores_avg)\n",
    "\n",
    "print(\"Naive Bayes Scores with Mode Filling:\", nb_mode_scores_avg)\n",
    "print(\"Naive Bayes Scores with Median Filling:\", nb_median_scores_avg)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 Findings + Discussion:\n",
    "\n",
    "\n",
    "**[DELETE ME] Remember to discuss the following:**\n",
    "\n",
    "* Discuss your outcomes from using your chosen preprocessing steps to handle missing data.\n",
    "* Compare the performance of both models and discuss their strengths and weaknesses. Which model is more suited for this dataset and why?\n",
    "* Insights gained from your experiments.\n",
    "\n",
    "#### Outcomes Discussion\n",
    "After completing the creating and analysis of the models, I found some rather odd results come from both models, in terms of the different filling methods I chose to use for NaN values. After creating two different dataframes for representing either filling method, I found that the average scores were identical for both of the different filling methods. This was rather odd to me, as I had ensured to account for any cases in which there were missing values. \n",
    "\n",
    "My workaround for this eventually led to slightly different values outputted from the logistic regression, however the Naive Bayes still continue to be identical. My workaround was that for the strategy involving the median replacement, I inputted logic to change the value of all NaN non-numerical values to 0. For the Mode replacement, I simply continued to make them the most frequent.\n",
    "\n",
    "Outside of this issue, my results providing some eye opening data depending on which score we choose to look at. For both accuracy and precision, we can see that the logistic regression model performs better, by a fairly decent margain in both instances. For the remaining metrics recall, f1, and roc auc, however, we can see that the Naive Bayes performs better by a smaller margain in all cases outside of recall, in which it was significantly better performing. \n",
    "\n",
    "What we can conclude from these outputs, is that Logistic Regression does a better job at predicting customers who do not churn since it considers less false positives, whereas Naive Bayes is better at predicting customers who do indeed churn. Based on the initial request, it seems fitting that we would use Naive Bayes as we are looking to identify as many churned customers as possible in order to minimize customer loss. \n",
    "\n",
    "Overall, I continued to learn just how powerful scikit-learn is, with all of the different function capabilities that can handpicked for nearly any scenario. It took a lot of trial and error to discover that some techniques I implemented are infact already automated, which was really an amazing discovery that I was able to go back and implement after the fact. Overall, super interesting experiment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "In this question, you will be **using k-means to perform image compression**. Implement a **naïve version** of the k-means algorithm based on your understanding. Your **code must take the number of clusters k as input and perform k-means clustering on the given image** (test_image.png). Once the algorithm finishes running, the cluster centroids represent the top-k common colors in the image. **Iterate through each pixel in the image and assign the closest color to each pixel. Save and visualize the resulting image.** For reading and writing images, you can use OpenCV, which is an open-source computer vision toolkit. The following code will load the image into a NumPy array. You can use this as input to your K-Means algorithm.\n",
    "\n",
    "<br/>\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "img = cv2.imread(‘test_image.png’)\n",
    "height, width, channels = np.shape(img)\n",
    "for i in width:\n",
    "    for j in height:\n",
    "        pixel = img[j][i] # Read the pixel at location (i,j)\n",
    "        img[j][i] = newValue # Assign a new value to the pixel\n",
    "```\n",
    "\n",
    "<br/>\n",
    "\n",
    "Experiment with different values of k and briefly describe your thoughts about which value works best for this problem. You can use plots, error bars, etc. to support your conclusions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "* Question 2 Code\n",
    "'''\n",
    "import cv2\n",
    "img = cv2.imread('/test_image.png')\n",
    "height, width, channels = np.shape(img)\n",
    "for i in width:\n",
    "    for j in height:\n",
    "        pixel = img[j][i] # Read the pixel at location (i,j)\n",
    "        img[j][i] = newValue # Assign a new value to the pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 Findings + Discussion:\n",
    "\n",
    "**[DELETE ME] Remember to discuss the following:**\n",
    "\n",
    "* [DELETE ME] Experiment with different values of k and briefly describe your thoughts about which value works best for this problem. You can use plots, error bars, etc. to support your conclusions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (pipx-jupyter)",
   "language": "python",
   "name": "pipx-jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
