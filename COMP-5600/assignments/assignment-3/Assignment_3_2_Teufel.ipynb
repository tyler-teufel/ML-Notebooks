{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sphjoM7vIgQi"
   },
   "source": [
    "# AI Assignment 3, part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6SdgJ5JIjDI"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kagglehub\n",
      "  Downloading kagglehub-0.3.4-py3-none-any.whl (43 kB)\n",
      "     ---------------------------------------- 43.0/43.0 kB ? eta 0:00:00\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.0-py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.6/78.6 kB ? eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\tyler\\appdata\\roaming\\python\\python310\\site-packages (from kagglehub) (24.2)\n",
      "Collecting requests\n",
      "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "     ---------------------------------------- 64.9/64.9 kB 3.4 MB/s eta 0:00:00\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.4.0-cp310-cp310-win_amd64.whl (102 kB)\n",
      "     ---------------------------------------- 102.2/102.2 kB ? eta 0:00:00\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "     ---------------------------------------- 126.3/126.3 kB ? eta 0:00:00\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "     ---------------------------------------- 70.4/70.4 kB ? eta 0:00:00\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "     ---------------------------------------- 167.3/167.3 kB ? eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\tyler\\appdata\\roaming\\python\\python310\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
      "Installing collected packages: urllib3, tqdm, idna, charset-normalizer, certifi, requests, kagglehub\n",
      "Successfully installed certifi-2024.8.30 charset-normalizer-3.4.0 idna-3.10 kagglehub-0.3.4 requests-2.32.3 tqdm-4.67.0 urllib3-2.2.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script tqdm.exe is installed in 'c:\\Users\\tyler\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script normalizer.exe is installed in 'c:\\Users\\tyler\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp310-cp310-win_amd64.whl (7.5 kB)\n",
      "Collecting tensorflow-intel==2.18.0\n",
      "  Downloading tensorflow_intel-2.18.0-cp310-cp310-win_amd64.whl (390.0 MB)\n",
      "     ------------------------------------- 390.0/390.0 MB 12.6 MB/s eta 0:00:00\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "     --------------------------------------- 26.4/26.4 MB 54.4 MB/s eta 0:00:00\n",
      "Collecting flatbuffers>=24.3.25\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "     ---------------------------------------- 71.9/71.9 kB ? eta 0:00:00\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\tyler\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Collecting keras>=3.5.0\n",
      "  Downloading keras-3.6.0-py3-none-any.whl (1.2 MB)\n",
      "     ---------------------------------------- 1.2/1.2 MB 73.8 MB/s eta 0:00:00\n",
      "Collecting tensorboard<2.19,>=2.18\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "     ---------------------------------------- 5.5/5.5 MB 59.1 MB/s eta 0:00:00\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0\n",
      "  Downloading ml_dtypes-0.4.1-cp310-cp310-win_amd64.whl (126 kB)\n",
      "     ---------------------------------------- 126.6/126.6 kB ? eta 0:00:00\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3\n",
      "  Downloading protobuf-5.28.3-cp310-abi3-win_amd64.whl (431 kB)\n",
      "     ------------------------------------- 431.5/431.5 kB 28.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\tyler\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\tyler\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.68.0-cp310-cp310-win_amd64.whl (4.4 MB)\n",
      "     ---------------------------------------- 4.4/4.4 MB 70.8 MB/s eta 0:00:00\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.16.0-cp310-cp310-win_amd64.whl (37 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 46.1 MB/s eta 0:00:00\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\tyler\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (63.2.0)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 57.5/57.5 kB 3.0 MB/s eta 0:00:00\n",
      "Collecting numpy<2.1.0,>=1.26.0\n",
      "  Downloading numpy-2.0.2-cp310-cp310-win_amd64.whl (15.9 MB)\n",
      "     --------------------------------------- 15.9/15.9 MB 18.2 MB/s eta 0:00:00\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "     ---------------------------------------- 133.7/133.7 kB ? eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\tyler\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Collecting h5py>=3.11.0\n",
      "  Downloading h5py-3.12.1-cp310-cp310-win_amd64.whl (3.0 MB)\n",
      "     ---------------------------------------- 3.0/3.0 MB 96.1 MB/s eta 0:00:00\n",
      "Collecting wheel<1.0,>=0.23.0\n",
      "  Downloading wheel-0.45.0-py3-none-any.whl (72 kB)\n",
      "     ---------------------------------------- 72.5/72.5 kB ? eta 0:00:00\n",
      "Collecting optree\n",
      "  Downloading optree-0.13.1-cp310-cp310-win_amd64.whl (282 kB)\n",
      "     ------------------------------------- 282.7/282.7 kB 17.0 MB/s eta 0:00:00\n",
      "Collecting namex\n",
      "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Collecting rich\n",
      "  Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "     ---------------------------------------- 242.4/242.4 kB ? eta 0:00:00\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\tyler\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\tyler\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tyler\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tyler\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.8.30)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "     ---------------------------------------- 106.3/106.3 kB ? eta 0:00:00\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "     ------------------------------------- 224.5/224.5 kB 13.4 MB/s eta 0:00:00\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Downloading MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl (15 kB)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "     ---------------------------------------- 87.5/87.5 kB ? eta 0:00:00\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\tyler\\appdata\\roaming\\python\\python310\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, numpy, mdurl, MarkupSafe, markdown, grpcio, google-pasta, gast, absl-py, werkzeug, ml-dtypes, markdown-it-py, h5py, astunparse, tensorboard, rich, keras, tensorflow-intel, tensorflow\n",
      "Successfully installed MarkupSafe-3.0.2 absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.68.0 h5py-3.12.1 keras-3.6.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 numpy-2.0.2 opt-einsum-3.4.0 optree-0.13.1 protobuf-5.28.3 rich-13.9.4 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-intel-2.18.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.5.0 werkzeug-3.1.3 wheel-0.45.0 wrapt-1.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script wheel.exe is installed in 'c:\\Users\\tyler\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts f2py.exe and numpy-config.exe are installed in 'c:\\Users\\tyler\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script markdown_py.exe is installed in 'c:\\Users\\tyler\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script markdown-it.exe is installed in 'c:\\Users\\tyler\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tensorboard.exe is installed in 'c:\\Users\\tyler\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts import_pb_to_tensorboard.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe, toco.exe and toco_from_protos.exe are installed in 'c:\\Users\\tyler\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp310-cp310-win_amd64.whl (11.6 MB)\n",
      "     --------------------------------------- 11.6/11.6 MB 72.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\tyler\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "     ---------------------------------------- 508.0/508.0 kB ? eta 0:00:00\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "     ------------------------------------- 346.6/346.6 kB 21.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\tyler\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tyler\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 pytz-2024.2 tzdata-2024.2\n",
      "Requirement already satisfied: numpy in c:\\users\\tyler\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.0.2)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.9.2-cp310-cp310-win_amd64.whl (7.8 MB)\n",
      "     ---------------------------------------- 7.8/7.8 MB 45.4 MB/s eta 0:00:00\n",
      "Collecting pillow>=8\n",
      "  Downloading pillow-11.0.0-cp310-cp310-win_amd64.whl (2.6 MB)\n",
      "     ---------------------------------------- 2.6/2.6 MB 54.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\tyler\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.3.1-cp310-cp310-win_amd64.whl (218 kB)\n",
      "     ---------------------------------------- 218.6/218.6 kB ? eta 0:00:00\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Downloading kiwisolver-1.4.7-cp310-cp310-win_amd64.whl (55 kB)\n",
      "     ---------------------------------------- 55.9/55.9 kB ? eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\tyler\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (24.2)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Downloading pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "     -------------------------------------- 106.9/106.9 kB 6.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\tyler\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (2.0.2)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.55.0-cp310-cp310-win_amd64.whl (2.2 MB)\n",
      "     ---------------------------------------- 2.2/2.2 MB 71.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tyler\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.55.0 kiwisolver-1.4.7 matplotlib-3.9.2 pillow-11.0.0 pyparsing-3.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts fonttools.exe, pyftmerge.exe, pyftsubset.exe and ttx.exe are installed in 'c:\\Users\\tyler\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 48.2 MB/s eta 0:00:00\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading regex-2024.11.6-cp310-cp310-win_amd64.whl (274 kB)\n",
      "     ---------------------------------------- 274.0/274.0 kB ? eta 0:00:00\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "     ---------------------------------------- 301.8/301.8 kB ? eta 0:00:00\n",
      "Collecting click\n",
      "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "     ---------------------------------------- 97.9/97.9 kB ? eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\users\\tyler\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (4.67.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\tyler\\appdata\\roaming\\python\\python310\\site-packages (from click->nltk) (0.4.6)\n",
      "Installing collected packages: regex, joblib, click, nltk\n",
      "Successfully installed click-8.1.7 joblib-1.4.2 nltk-3.9.1 regex-2024.11.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script nltk.exe is installed in 'c:\\Users\\tyler\\AppData\\Local\\Programs\\Python\\Python310\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.2-cp310-cp310-win_amd64.whl (11.0 MB)\n",
      "     --------------------------------------- 11.0/11.0 MB 65.5 MB/s eta 0:00:00\n",
      "Collecting scipy>=1.6.0\n",
      "  Downloading scipy-1.14.1-cp310-cp310-win_amd64.whl (44.8 MB)\n",
      "     --------------------------------------- 44.8/44.8 MB 27.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\tyler\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (2.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\tyler\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn\n",
      "Successfully installed scikit-learn-1.5.2 scipy-1.14.1 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.10.0.84-cp37-abi3-win_amd64.whl (38.8 MB)\n",
      "     --------------------------------------- 38.8/38.8 MB 54.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\tyler\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from opencv-python) (2.0.2)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.10.0.84\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install kagglehub\n",
    "%pip install tensorflow\n",
    "%pip install pandas\n",
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install nltk\n",
    "%pip install scikit-learn\n",
    "%pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LzhuKP8GIo6q"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tyler\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, Input\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k9Ekpf2jJAOQ"
   },
   "source": [
    "## Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iv1KeqyhMQ5V"
   },
   "source": [
    "### Download the data, pull the directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W_7VWTEeR4uw",
    "outputId": "0697f677-ba00-47a4-c7a2-9b83780fc846"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/puneet6060/intel-image-classification?dataset_version_number=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 346M/346M [00:08<00:00, 44.7MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/tylerteufel/.cache/kagglehub/datasets/puneet6060/intel-image-classification/versions/2\n",
      "Train directory: /Users/tylerteufel/.cache/kagglehub/datasets/puneet6060/intel-image-classification/versions/2/seg_train/seg_train\n",
      "Test directory: /Users/tylerteufel/.cache/kagglehub/datasets/puneet6060/intel-image-classification/versions/2/seg_test/seg_test\n"
     ]
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"puneet6060/intel-image-classification\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "train_dir = os.path.join(path, 'seg_train/seg_train')\n",
    "test_dir = os.path.join(path, 'seg_test/seg_test')\n",
    "\n",
    "print(\"Train directory:\", train_dir)\n",
    "print(\"Test directory:\", test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GqfzDdhKMUXl"
   },
   "source": [
    "### Define load_images function for identifying by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jZP45WwRQvu4",
    "outputId": "8b00a53f-8ecc-4883-c5d5-c7fc1cf310af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (14034, 128, 128, 3)\n",
      "Validation data shape: (3000, 128, 128, 3)\n",
      "Classes: ['forest', 'buildings', 'glacier', 'street', 'mountain', 'sea']\n",
      "Shape of Y_train: (14034,)\n",
      "Shape of Y_val: (3000,)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "def load_images(folder):\n",
    "\n",
    "  images = []\n",
    "  labels = []\n",
    "  class_names = os.listdir(folder)\n",
    "  class_indices = {class_name: i for i, class_name in enumerate(class_names)}\n",
    "\n",
    "  for class_name in class_names:\n",
    "    class_folder = os.path.join(folder, class_name)\n",
    "    if os.path.isdir(class_folder):\n",
    "      for image_name in os.listdir(class_folder):\n",
    "        image_path = os.path.join(class_folder, image_name)\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is not None:\n",
    "          image = cv2.resize(image, (128, 128))\n",
    "          images.append(image)\n",
    "          labels.append(class_indices[class_name])\n",
    "\n",
    "  return np.array(images), np.array(labels), class_names\n",
    "\n",
    "X_train, Y_train, train_class_names = load_images(train_dir)\n",
    "\n",
    "X_val, Y_val, val_class_names = load_images(test_dir)\n",
    "\n",
    "print('Training data shape:', X_train.shape)\n",
    "print('Validation data shape:', X_val.shape)\n",
    "print('Classes:', train_class_names)\n",
    "\n",
    "print(\"Shape of Y_train:\", Y_train.shape)  # Should be (14034, num_classes)\n",
    "print(\"Shape of Y_val:\", Y_val.shape)      # Should be (3000, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGtcqbhJUw5N"
   },
   "source": [
    "### Normalize image pixel values, use one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NcuMC-JGT-mK",
    "outputId": "db9ef66e-d706-403e-d2fe-ce772bee53db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Y_train after encoding: (14034, 6)\n",
      "Shape of Y_val after encoding: (3000, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train / 255.0\n",
    "X_val = X_val / 255.0\n",
    "\n",
    "Y_train = to_categorical(Y_train, num_classes=len(train_class_names))\n",
    "Y_val = to_categorical(Y_val, num_classes=len(val_class_names))\n",
    "\n",
    "# Verify the shapes after encoding\n",
    "print(\"Shape of Y_train after encoding:\", Y_train.shape)  # Should be (14034, 6)\n",
    "print(\"Shape of Y_val after encoding:\", Y_val.shape)      # Should be (3000, 6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2mjOTqPU9Mt"
   },
   "source": [
    "## Train CNN Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91y8Y2LRVGfw"
   },
   "source": [
    "### Model 1: 3 convolution layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uQ4fubwVVIrm",
    "outputId": "ee13d43c-ee4a-4235-dcde-ef5f18e09805"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 220ms/step - accuracy: 0.4917 - loss: 1.2632 - val_accuracy: 0.6943 - val_loss: 0.8348\n",
      "Epoch 2/10\n",
      "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 199ms/step - accuracy: 0.6876 - loss: 0.8373 - val_accuracy: 0.7420 - val_loss: 0.6808\n",
      "Epoch 3/10\n",
      "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 220ms/step - accuracy: 0.7744 - loss: 0.6399 - val_accuracy: 0.8003 - val_loss: 0.5624\n",
      "Epoch 4/10\n",
      "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 209ms/step - accuracy: 0.8007 - loss: 0.5511 - val_accuracy: 0.8330 - val_loss: 0.4785\n",
      "Epoch 5/10\n",
      "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 198ms/step - accuracy: 0.8453 - loss: 0.4373 - val_accuracy: 0.8377 - val_loss: 0.4809\n",
      "Epoch 6/10\n",
      "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 191ms/step - accuracy: 0.8684 - loss: 0.3787 - val_accuracy: 0.8237 - val_loss: 0.5461\n",
      "Epoch 7/10\n",
      "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 183ms/step - accuracy: 0.8850 - loss: 0.3163 - val_accuracy: 0.8270 - val_loss: 0.5375\n",
      "Epoch 8/10\n",
      "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 184ms/step - accuracy: 0.9044 - loss: 0.2679 - val_accuracy: 0.8277 - val_loss: 0.5524\n",
      "Epoch 9/10\n",
      "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 176ms/step - accuracy: 0.9121 - loss: 0.2483 - val_accuracy: 0.8123 - val_loss: 0.6674\n",
      "Epoch 10/10\n",
      "\u001b[1m439/439\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 178ms/step - accuracy: 0.9280 - loss: 0.1965 - val_accuracy: 0.8370 - val_loss: 0.6152\n"
     ]
    }
   ],
   "source": [
    "model_3conv = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(train_class_names), activation='softmax')\n",
    "\n",
    "])\n",
    "\n",
    "model_3conv.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history_3conv = model_3conv.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t2wTS1iCs8CX"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_class_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 14\u001b[0m\n\u001b[0;32m      1\u001b[0m model_6conv \u001b[38;5;241m=\u001b[39m Sequential([\n\u001b[0;32m      2\u001b[0m     Conv2D(\u001b[38;5;241m32\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m3\u001b[39m)),\n\u001b[0;32m      3\u001b[0m     Conv2D(\u001b[38;5;241m32\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      4\u001b[0m     MaxPooling2D(pool_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)),\n\u001b[0;32m      5\u001b[0m     Conv2D(\u001b[38;5;241m64\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      6\u001b[0m     Conv2D(\u001b[38;5;241m64\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      7\u001b[0m     MaxPooling2D(pool_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)),\n\u001b[0;32m      8\u001b[0m     Conv2D(\u001b[38;5;241m128\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m      9\u001b[0m     Conv2D(\u001b[38;5;241m128\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     10\u001b[0m     MaxPooling2D(pool_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)),\n\u001b[0;32m     11\u001b[0m     Flatten(),\n\u001b[0;32m     12\u001b[0m     Dense(\u001b[38;5;241m256\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     13\u001b[0m     Dropout(\u001b[38;5;241m0.5\u001b[39m),\n\u001b[1;32m---> 14\u001b[0m     Dense(\u001b[38;5;28mlen\u001b[39m(\u001b[43mtrain_class_names\u001b[49m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m ])\n\u001b[0;32m     18\u001b[0m model_6conv\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_class_names' is not defined"
     ]
    }
   ],
   "source": [
    "model_6conv = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(train_class_names), activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model_6conv.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history_6conv = model_6conv.fit(\n",
    "    X_train, Y_train, \n",
    "    validation_data=(X_val, Y_val), \n",
    "    epochs=10, \n",
    "    batch_size=32\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-BXf2U2fVA84"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "_6SdgJ5JIjDI",
    "k9Ekpf2jJAOQ",
    "Iv1KeqyhMQ5V"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
